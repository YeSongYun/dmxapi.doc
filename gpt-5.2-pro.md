# OpenAI Response æ¥å£æ ¼å¼è°ƒç”¨

## æ¥å£åœ°å€

```
https://www.dmxapi.cn/v1/responses
```

## æ¨¡å‹åç§°

- `gpt-5.2-pro`
- `gpt-5-pro`


## è°ƒç”¨ç¤ºä¾‹

```python
import requests
import json

# ============================================================================
# é…ç½®éƒ¨åˆ† - API è¿æ¥ä¿¡æ¯
# ============================================================================

# DMXAPI çš„ URL åœ°å€
url = "https://www.dmxapi.cn/v1/responses"

# API å¯†é’¥ - ç”¨äºèº«ä»½éªŒè¯å’Œè®¿é—®æ§åˆ¶
api_key = "sk-***************************"  # âš ï¸ è¯·æ›¿æ¢ä¸ºä½ çš„APIå¯†é’¥

# ============================================================================
# è¯·æ±‚å¤´é…ç½® - è®¾ç½®å†…å®¹ç±»å‹å’Œæˆæƒä¿¡æ¯
# ============================================================================
headers = {
    "Content-Type": "application/json",      # æŒ‡å®šè¯·æ±‚ä½“ä¸º JSON æ ¼å¼
    "Authorization": f"{api_key}",    # token è®¤è¯æ–¹å¼
}

# ============================================================================
# è¯·æ±‚å‚æ•°é…ç½® - AI æ¨¡å‹ä¸è¾“å…¥å†…å®¹
# ============================================================================
data = {
    # ---------- åŸºç¡€é…ç½® ----------
    "model": "gpt-5.2-pro",    # æŒ‡å®šä½¿ç”¨çš„ AI æ¨¡å‹ç‰ˆæœ¬
    "input": "ä½ å¥½",          # å‘é€ç»™ AI çš„é—®é¢˜æˆ–æŒ‡ä»¤
    "stream": True,          # å¯ç”¨æµå¼è¾“å‡º - å®æ—¶æ¥æ”¶å“åº”è€Œä¸æ˜¯ç­‰å¾…å®Œæ•´å›å¤
    
    # ---------- è¾“å‡ºæ§åˆ¶å‚æ•° ----------
    # ğŸ“ æœ€å¤§è¾“å‡ºä»¤ç‰Œæ•° 
    # æ§åˆ¶æ¨¡å‹å“åº”çš„æœ€å¤§é•¿åº¦
    # ğŸ’¡ æç¤º: å®é™…è¾“å‡ºå¯èƒ½å°‘äºæ­¤å€¼
    "max_output_tokens": 128000,

    # ---------- é‡‡æ ·å‚æ•° ----------
    # ğŸŒ¡ï¸ æ¸©åº¦å‚æ•° (èŒƒå›´: 0.0 - 2.0)
    # æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§å’Œåˆ›é€ æ€§:
    #   â€¢ è¾ƒä½å€¼ (0.0-0.3): è¾“å‡ºæ›´ç¡®å®šã€æ›´ä¸€è‡´,é€‚åˆäº‹å®æ€§ä»»åŠ¡
    #   â€¢ ä¸­ç­‰å€¼ (0.4-0.8): å¹³è¡¡åˆ›é€ æ€§å’Œä¸€è‡´æ€§
    #   â€¢ è¾ƒé«˜å€¼ (0.9-2.0): è¾“å‡ºæ›´éšæœºã€æ›´æœ‰åˆ›æ„
    # âš ï¸ å»ºè®®: åªè°ƒæ•´ temperature æˆ– top_p å…¶ä¸­ä¹‹ä¸€
    "temperature": 1,

    # ğŸ¯ æ ¸é‡‡æ ·å‚æ•° (èŒƒå›´: 0.0 - 1.0)
    # æ§åˆ¶é‡‡æ ·çš„æ¦‚ç‡è´¨é‡é˜ˆå€¼:
    #   â€¢ 0.1: åªè€ƒè™‘æ¦‚ç‡æœ€é«˜çš„ 10% çš„è¯
    #   â€¢ 0.5: åªè€ƒè™‘æ¦‚ç‡æœ€é«˜çš„ 50% çš„è¯
    #   â€¢ 1.0: è€ƒè™‘æ‰€æœ‰å¯èƒ½çš„è¯
    # ğŸ’¡ æç¤º: è¾ƒä½çš„å€¼ä¼šè®©è¾“å‡ºæ›´é›†ä¸­,è¾ƒé«˜çš„å€¼ä¼šå¢åŠ å¤šæ ·æ€§
    # âš ï¸ å»ºè®®: åªè°ƒæ•´ temperature æˆ– top_p å…¶ä¸­ä¹‹ä¸€
    "top_p": 1,
    
    # ---------- æ¨ç†é…ç½® ----------

    "reasoning": {
  
        # ğŸ“Œ æ³¨æ„: gpt-5.2-pro æ¨¡å‹é»˜è®¤ä¸”ä»…æ”¯æŒ high çº§åˆ«
        "effort": "high"
    }
}

# ============================================================================
# å‘é€è¯·æ±‚å¹¶å¤„ç†æµå¼å“åº”
# ============================================================================

# å‘é€ POST è¯·æ±‚åˆ° API æœåŠ¡å™¨,å¯ç”¨æµå¼å“åº”æ¨¡å¼
response = requests.post(url, headers=headers, json=data, stream=True)

# ----------------------------------------------------------------------------
# å¤„ç†æµå¼å“åº” - å®æ—¶è§£ææœåŠ¡å™¨è¿”å›çš„æ•°æ®æµ
# ----------------------------------------------------------------------------
try:
    # åˆå§‹åŒ–å˜é‡ç”¨äºè·Ÿè¸ªå½“å‰äº‹ä»¶å’Œæ•°æ®
    current_event = None    # å½“å‰ SSE äº‹ä»¶ç±»å‹
    current_data = None     # å½“å‰ SSE äº‹ä»¶æ•°æ®
    
    # é€è¡Œè¯»å–å“åº”æµ - å¤„ç†æœåŠ¡å™¨å‘é€çš„æ¯ä¸€è¡Œæ•°æ®
    for line in response.iter_lines():
        if line:  # å¦‚æœè¡Œä¸ä¸ºç©º
            # è§£ç å­—èŠ‚æ•°æ®ä¸º UTF-8 å­—ç¬¦ä¸²å¹¶å»é™¤é¦–å°¾ç©ºç™½
            line_text = line.decode('utf-8').strip()
            
            # ---- å¤„ç† SSE (Server-Sent Events) æ ¼å¼çš„äº‹ä»¶æµ ----
            if line_text.startswith('event: '):
                # è§£æäº‹ä»¶ç±»å‹ - æå–äº‹ä»¶åç§°
                current_event = line_text[7:]  
                
            elif line_text.startswith('data: '):
                # è§£æäº‹ä»¶æ•°æ® - æå–æ•°æ®å†…å®¹
                current_data = line_text[6:]  
                
                # åªå¤„ç†åŒ…å«æ–‡æœ¬å†…å®¹çš„å¢é‡äº‹ä»¶
                if current_event == 'response.output_text.delta' and current_data:
                    try:
                        # è§£æ JSON æ•°æ® - å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º Python å­—å…¸
                        json_data = json.loads(current_data)
                        
                        # æå–æ–‡æœ¬å†…å®¹ - æ ¹æ®å®é™…æ•°æ®ç»“æ„,æ–‡æœ¬åœ¨ delta å­—æ®µä¸­
                        if 'delta' in json_data:
                            content = json_data['delta']    # è·å–å¢é‡æ–‡æœ¬å†…å®¹
                            if content:
                                # å®æ—¶æ‰“å°æ–‡æœ¬å†…å®¹ - ä¸æ¢è¡Œ,ç«‹å³åˆ·æ–°è¾“å‡ºç¼“å†²åŒº
                                print(content, end='', flush=True)
                                
                    except json.JSONDecodeError:
                        # é™é»˜å¤„ç† JSON è§£æé”™è¯¯ - é¿å…å¹²æ‰°æ­£å¸¸è¾“å‡º
                        pass
                        
            elif line_text == '':
                # ç©ºè¡Œè¡¨ç¤ºä¸€ä¸ªäº‹ä»¶ç»“æŸ - é‡ç½®äº‹ä»¶çŠ¶æ€
                current_event = None
                current_data = None

# ----------------------------------------------------------------------------
# å¼‚å¸¸å¤„ç†
# ----------------------------------------------------------------------------
except KeyboardInterrupt:
    # å¤„ç†ç”¨æˆ·ä¸­æ–­ - å½“ç”¨æˆ·æŒ‰ Ctrl+C æ—¶ä¼˜é›…é€€å‡º
    print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†è¯·æ±‚")
    
except Exception as e:
    # å¤„ç†å…¶ä»–å¼‚å¸¸ - æ•è·å¹¶æ˜¾ç¤ºä»»ä½•æ„å¤–é”™è¯¯
    print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {e}")

# æœ€åæ¢è¡Œ - ç¡®ä¿è¾“å‡ºæ ¼å¼æ•´æ´
print()

```

## è¿”å›ç¤ºä¾‹

```json
{
  "id": "resp_0bc0cffd983db63400693fdeadd58481a2aa83ef0faac36caf",
  "created_at": 1765793453.0,
  "error": null,
  "incomplete_details": null,
  "instructions": null,
  "metadata": {},
  "model": "gpt-5.2-pro",
  "object": "response",
  "output": [
    {
      "id": "msg_0bc0cffd983db63400693fdeb7040881a2a3bab41b1908bdd8",
      "content": [
        {
          "annotations": [],
          "text": "ä½ å¥½ï¼æˆ‘èƒ½å¸®ä½ åšäº›ä»€ä¹ˆï¼Ÿå¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥å‘Šè¯‰æˆ‘ä½ æƒ³èŠçš„ä¸»é¢˜æˆ–éœ€è¦è§£å†³çš„é—®é¢˜ï¼ˆæ¯”å¦‚å­¦ä¹ ã€å†™ä½œã€ç¼–ç¨‹ã€ç¿»è¯‘ã€ç”Ÿæ´»å»ºè®®ç­‰ï¼‰ã€‚",
          "type": "output_text",
          "logprobs": []
        }
      ],
      "role": "assistant",
      "status": "completed",
      "type": "message"
    }
  ],
  "parallel_tool_calls": true,
  "temperature": 1.0,
  "tool_choice": "auto",
  "tools": [],
  "top_p": 0.98,
  "background": false,
  "conversation": null,
  "max_output_tokens": null,
  "max_tool_calls": null,
  "previous_response_id": null,
  "prompt": null,
  "prompt_cache_key": null,
  "prompt_cache_retention": null,
  "reasoning": {
    "effort": "high",
    "generate_summary": null,
    "summary": null
  },
  "safety_identifier": null,
  "service_tier": "default",
  "status": "completed",
  "text": {
    "format": {
      "type": "text"
    },
    "verbosity": "medium"
  },
  "top_logprobs": 0,
  "truncation": "disabled",
  "usage": {
    "input_tokens": 8,
    "input_tokens_details": {
      "cached_tokens": 0
    },
    "output_tokens": 46,
    "output_tokens_details": {
      "reasoning_tokens": 0
    },
    "total_tokens": 54
  },
  "user": null,
  "billing": {
    "payer": "developer"
  },
  "store": true
}
```

## æ³¨æ„äº‹é¡¹

1. **APIå¯†é’¥å®‰å…¨**: è¯·å¦¥å–„ä¿ç®¡æ‚¨çš„APIå¯†é’¥,ä¸è¦æ³„éœ²
2. **æ¥å£æ ¼å¼è¦æ±‚**: `gpt-5.2-pro` æ¨¡å‹å¿…é¡»ä½¿ç”¨ `response` æ¥å£æ ¼å¼è°ƒç”¨
3. **æµ‹è¯•å»ºè®®**: å»ºè®®åœ¨æ­£å¼ç¯å¢ƒå‰å…ˆè¿›è¡Œæµ‹è¯•è°ƒç”¨
4. **æŠ€æœ¯æ”¯æŒ**: å¦‚é‡é—®é¢˜å¯è”ç³» DMXAPI æŠ€æœ¯æ”¯æŒ

---

<p align="center">
  <small>Â© 2025 DMXAPI OpenAI æ–°æ¥å£</small>
</p>