# LangChain

## LangChain é›†æˆç¤ºä¾‹1
LangChainå‡çº§é¢‘ç¹ï¼Œå¹¶ä¸”ä¼šæœ‰ç ´åæ€§æ›´æ–°ï¼Œè¯·æ³¨æ„ç‰ˆæœ¬åŒºåˆ«ã€‚
```python
"""
LangChain ç»“æ„åŒ–è¾“å‡ºç¤ºä¾‹ï¼šè‡ªç„¶è¯­è¨€è½¬è®¡ç®—æ­¥éª¤

åŠŸèƒ½æ¦‚è¿°ï¼š
    æœ¬è„šæœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ LangChain å°†è‡ªç„¶è¯­è¨€æè¿°è½¬æ¢ä¸ºç»“æ„åŒ–çš„ JSON æ•°æ®ï¼Œ
    é€šè¿‡ Pydantic æ¨¡å‹å®ç°å¼ºç±»å‹æ ¡éªŒï¼Œç¡®ä¿è¾“å‡ºç¬¦åˆé¢„æœŸæ ¼å¼ã€‚

æ ¸å¿ƒèƒ½åŠ›ï¼š
    - è°ƒç”¨å…¼å®¹ OpenAI æ¥å£çš„ DMXAPI æœåŠ¡
    - ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºï¼ˆStructured Outputï¼‰æ¨¡å¼
    - é€šè¿‡ Pydantic è¿›è¡Œæ•°æ®éªŒè¯å’Œç±»å‹æ£€æŸ¥
    - å¼‚æ­¥æ‰§è¡Œï¼Œæé«˜å¤„ç†æ•ˆç‡

é€‚ç”¨åœºæ™¯ï¼š
    - å°†ä¸šåŠ¡æµç¨‹æè¿°è½¬ä¸ºå¯æ‰§è¡Œæ­¥éª¤
    - è§£æå¤æ‚çš„è®¡ç®—é€»è¾‘
    - éœ€è¦ä¸¥æ ¼æ•°æ®æ ¼å¼çš„ AI åº”ç”¨
"""

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from pydantic import BaseModel, Field
from typing import List
import asyncio


# ==================== æ¨¡å‹é…ç½® ====================

llm = ChatOpenAI(
    api_key="sk-*********************************",  # æ›¿æ¢ä¸ºæ‚¨çš„ DMXAPI å¯†é’¥
    base_url="https://www.dmxapi.cn/v1",
    model="gemini-2.5-flash", )


# ==================== æ•°æ®æ¨¡å‹å®šä¹‰ ====================

class CalculationStep(BaseModel):
    """å•ä¸ªè®¡ç®—æ­¥éª¤çš„æ•°æ®ç»“æ„"""

    step_idx: int = Field(
        description="æ­¥éª¤åºå·ï¼ˆä» 1 å¼€å§‹ï¼‰"
    )
    pseudocode: str = Field(
        description="æ­¥éª¤çš„ä¼ªä»£ç æˆ–è‡ªç„¶è¯­è¨€æè¿°"
    )

    model_config = {
        "json_schema_extra": {
            "examples": [{
                "step_idx": 1,
                "pseudocode": "è®¡ç®—5æ—¥å¯¹æ•°æ”¶ç›Šç‡"
            }]
        }
    }


class DecoupledSteps(BaseModel):
    """å®Œæ•´çš„è®¡ç®—æ­¥éª¤åˆ—è¡¨å®¹å™¨"""

    steps: List[CalculationStep] = Field(
        description="æ‰€æœ‰è®¡ç®—æ­¥éª¤çš„æœ‰åºåˆ—è¡¨"
    )

    model_config = {
        "json_schema_extra": {
            "examples": [{
                "steps": [
                    {"step_idx": 1, "pseudocode": "è®¡ç®—5æ—¥å¯¹æ•°æ”¶ç›Šç‡"},
                    {"step_idx": 2, "pseudocode": "å¯¹ä¸Šä¸€æ­¥çš„ç»“æœå–åå¾—åˆ°åè½¬å› å­"}
                ]
            }]
        }
    }


# ==================== ä¸»ç¨‹åºé€»è¾‘ ====================

async def main():
    """
    å¼‚æ­¥ä¸»å‡½æ•°ï¼šæ‰§è¡Œç»“æ„åŒ–è¾“å‡ºæµç¨‹

    æµç¨‹è¯´æ˜ï¼š
        1. å°† LLM åŒ…è£…ä¸ºç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
        2. æ„é€ ç”¨æˆ·æç¤ºè¯
        3. è°ƒç”¨æ¨¡å‹å¹¶è‡ªåŠ¨è§£æä¸º Pydantic å¯¹è±¡
        4. è¾“å‡ºç»“æ„åŒ–ç»“æœ
    """

    # å¯ç”¨ç»“æ„åŒ–è¾“å‡ºæ¨¡å¼ï¼ˆä½¿ç”¨ json_mode ä»¥å…¼å®¹æ›´å¤š API æä¾›å•†ï¼‰
    model = llm.with_structured_output(
        schema=DecoupledSteps,
        method="json_mode"
    )

    # æ„é€ ç”¨æˆ·æ¶ˆæ¯
    msgs = [
        HumanMessage(content="""å°†è¿™æ®µæ–‡æœ¬è½¬åŒ–ä¸ºæ ¼å¼åŒ–çš„è®¡ç®—æ­¥éª¤åˆ—è¡¨ï¼šè®¡ç®—5æ—¥å¯¹æ•°æ”¶ç›Šç‡ï¼Œç„¶åå–åå¾—åˆ°åè½¬å› å­

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{
  "steps": [
    {
      "step_idx": 1,
      "pseudocode": "è®¡ç®—5æ—¥å¯¹æ•°æ”¶ç›Šç‡"
    },
    {
      "step_idx": 2,
      "pseudocode": "å¯¹ä¸Šä¸€æ­¥çš„ç»“æœå–åå¾—åˆ°åè½¬å› å­"
    }
  ]
}

æ¯ä¸ªæ­¥éª¤å¿…é¡»åŒ…å«ï¼š
- step_idx: æ•´æ•°ç±»å‹çš„æ­¥éª¤åºå·ï¼ˆä»1å¼€å§‹ï¼‰
- pseudocode: å­—ç¬¦ä¸²ç±»å‹çš„ä¼ªä»£ç æè¿°""")
    ]

    # å¼‚æ­¥è°ƒç”¨å¹¶è¾“å‡ºç»“æœ
    result = await model.ainvoke(msgs)
    print(result)


# ==================== ç¨‹åºå…¥å£ ====================

if __name__ == "__main__":
    asyncio.run(main())
```
## LangChain è¿”å›ç¤ºä¾‹1
```json
steps=[CalculationStep(step_idx=1, pseudocode='è®¡ç®—5æ—¥å¯¹æ•°æ”¶ç›Šç‡'), CalculationStep(step_idx=2, pseudocode='å¯¹ä¸Šä¸€æ­¥çš„ç»“æœå–åå¾—åˆ°åè½¬å› å­')]
```

## LangChain é›†æˆç¤ºä¾‹2
LangChainå‡çº§é¢‘ç¹ï¼Œå¹¶ä¸”ä¼šæœ‰ç ´åæ€§æ›´æ–°ï¼Œè¯·æ³¨æ„ç‰ˆæœ¬åŒºåˆ«ã€‚
```python
"""
LangChain Agent å·¥å…·è°ƒç”¨ç¤ºä¾‹ï¼šæ™ºèƒ½å¤©æ°”åŠ©æ‰‹

åŠŸèƒ½æ¦‚è¿°ï¼š
    æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ LangChain åˆ›å»ºä¸€ä¸ªå¯è‡ªåŠ¨è°ƒç”¨å·¥å…·çš„æ™ºèƒ½ Agentï¼Œ
    å®ç°ä»ç”¨æˆ·è¾“å…¥åˆ°å·¥å…·æ‰§è¡Œå†åˆ°è‡ªç„¶è¯­è¨€å›å¤çš„å®Œæ•´æµç¨‹ã€‚

æ ¸å¿ƒèƒ½åŠ›ï¼š
    - åˆ›å»ºæ”¯æŒå·¥å…·è°ƒç”¨çš„ Agent
    - å®šä¹‰è‡ªå®šä¹‰å·¥å…·å‡½æ•°
    - é…ç½®ç³»ç»Ÿæç¤ºè¯æ§åˆ¶è¡Œä¸º
    - æ™ºèƒ½è§£æå¤šç§è¿”å›æ ¼å¼
    - å¼‚å¸¸å¤„ç†ä¸ç”¨æˆ·å‹å¥½æç¤º

é€‚ç”¨åœºæ™¯ï¼š
    - éœ€è¦è°ƒç”¨å¤–éƒ¨ API çš„å¯¹è¯ç³»ç»Ÿ
    - å¤šåŠŸèƒ½æ™ºèƒ½åŠ©æ‰‹
    - è‡ªåŠ¨åŒ–ä»»åŠ¡æ‰§è¡Œä»£ç†
"""

from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
import os


# ==================== æ¨¡å‹åˆå§‹åŒ– ====================

# ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å– API å¯†é’¥ï¼ˆå®‰å…¨æœ€ä½³å®è·µï¼‰
api_key = (
    os.getenv("DMXAPI_API_KEY") or
    os.getenv("OPENAI_API_KEY") or
    "sk-*********************************"  # æ›¿æ¢ä¸ºæ‚¨çš„å®é™…å¯†é’¥
)

if not api_key:
    print("[æç¤º] æœªæ£€æµ‹åˆ°å¯†é’¥ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ DMXAPI_API_KEY æˆ– OPENAI_API_KEY")

# åˆå§‹åŒ–å…¼å®¹ OpenAI æ¥å£çš„æ¨¡å‹
llm = ChatOpenAI(
    model="gpt-4o-mini",
    base_url="https://www.dmxapi.cn/v1",
    api_key=api_key,
)


# ==================== å·¥å…·å®šä¹‰ ====================

@tool
def get_weather(city: str) -> str:
    """
    æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯

    å‚æ•°ï¼š
        city: åŸå¸‚åç§°ï¼ˆä¸­æ–‡æˆ–è‹±æ–‡ï¼‰

    è¿”å›ï¼š
        å¤©æ°”æè¿°å­—ç¬¦ä¸²

    æ³¨æ„ï¼š
        è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å·¥å…·ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®ã€‚
        å®é™…åº”ç”¨ä¸­å¯æ¥å…¥çœŸå®å¤©æ°” APIï¼ˆå¦‚å’Œé£å¤©æ°”ã€OpenWeatherMapï¼‰ã€‚
    """
    return f"{city} ä»Šå¤©æ™´æœ—ï¼Œ25Â°Cï¼Œå¾®é£å¾å¾ã€‚"

# å·¥å…·åˆ—è¡¨ï¼ˆå¯æ‰©å±•æ›´å¤šå·¥å…·ï¼‰
tools = [get_weather]


# ==================== Agent é…ç½® ====================

system_prompt = """
ä½ æ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½æ™ºèƒ½åŠ©ç†ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¯·æ±‚ï¼Œ
è‡ªåŠ¨è°ƒç”¨å¯ç”¨å·¥å…·å¹¶ç”Ÿæˆå‹å¥½ã€æœ‰åˆ›æ„çš„å›ç­”ã€‚

ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·åŒ…æ‹¬ï¼š
- get_weather(city: str): ç”¨äºè·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ã€‚

ä½¿ç”¨ç­–ç•¥ï¼š
1. å½“ç”¨æˆ·è¯¢é—®å¤©æ°”æ—¶ï¼Œè¯·è‡ªåŠ¨è°ƒç”¨ get_weather å·¥å…·ã€‚
2. åœ¨è·å–ç»“æœåï¼Œå°†å¤©æ°”ä¿¡æ¯ç”¨è‡ªç„¶è¯­è¨€è½¬è¿°ã€‚
3. å¦‚æœç”¨æˆ·è¯·æ±‚ç”Ÿæˆæœ‹å‹åœˆæ–‡æ¡ˆï¼Œè¯·ç”Ÿæˆä¸€å¥å…·æœ‰æ–‡è‰ºæ°”æ¯çš„çŸ­å¥ã€‚
4. æœ€ç»ˆè¾“å‡ºè‡ªç„¶æµç•…çš„ä¸­æ–‡å›ç­”ï¼Œä¸æ˜¾ç¤ºå·¥å…·è°ƒç”¨è¿‡ç¨‹ã€‚

å›ç­”ç¤ºä¾‹ï¼š
ç”¨æˆ·ï¼š"æŸ¥ä¸‹åŒ—äº¬å¤©æ°”å¹¶å†™ä¸€å¥æœ‹å‹åœˆæ–‡æ¡ˆ"
å›ç­”ï¼š"åŒ—äº¬ä»Šå¤©æ™´æœ—ï¼Œå¾®é£ä¸ç‡¥ï¼Œæ¸©åº¦å®œäººã€‚è¿™æ ·çš„å¤©æ°”ï¼Œæœ€é€‚åˆæ™’æ™’å¿ƒæƒ…â˜€ï¸"
"""

# åˆ›å»º Agent å®ä¾‹
agent = create_agent(
    model=llm,
    tools=tools,
    system_prompt=system_prompt
)


# ==================== æ‰§è¡Œä¸è¾“å‡º ====================

def extract_output(response) -> str:
    """
    ä»ä¸åŒæ ¼å¼çš„ Agent å“åº”ä¸­æå–æ–‡æœ¬è¾“å‡º

    å…¼å®¹å¤šç§è¿”å›ç»“æ„ï¼š
        - å­—å…¸æ ¼å¼ï¼šoutput / final_output å­—æ®µ
        - LangGraph æ ¼å¼ï¼šmessages åˆ—è¡¨
        - å¯¹è±¡æ ¼å¼ï¼šcontent å±æ€§

    å‚æ•°ï¼š
        response: Agent è¿”å›çš„å“åº”å¯¹è±¡

    è¿”å›ï¼š
        æå–çš„æ–‡æœ¬å†…å®¹
    """
    if isinstance(response, dict):
        # ä¼˜å…ˆå°è¯•æ ‡å‡†å­—æ®µ
        output = response.get("output") or response.get("final_output")
        if output:
            return output

        # ä» messages åˆ—è¡¨ä¸­æå–
        messages = response.get("messages")
        if isinstance(messages, list) and messages:
            last_message = messages[-1]
            content = getattr(last_message, "content", None)

            if content is None and isinstance(last_message, dict):
                content = last_message.get("content")

            # å¤„ç†åˆ—è¡¨ç±»å‹çš„ content
            if isinstance(content, list):
                text_parts = []
                for part in content:
                    if isinstance(part, dict) and part.get("type") == "text":
                        text_parts.append(part["text"])
                    elif isinstance(part, str):
                        text_parts.append(part)
                if text_parts:
                    return "\n".join(text_parts)

            # å¤„ç†å­—ç¬¦ä¸²ç±»å‹çš„ content
            elif isinstance(content, str):
                return content

    # å…œåº•ç­–ç•¥
    return getattr(response, "content", None) or str(response)


# ä¸»æ‰§è¡Œæµç¨‹
try:
    response = agent.invoke({
        "input": "å¸®æˆ‘æŸ¥ä¸‹æ·±åœ³å¤©æ°”å¹¶å†™ä¸€å¥æ–‡è‰ºæœ‹å‹åœˆæ–‡æ¡ˆ"
    })

    output = extract_output(response)
    print("ğŸ¤– è¾“å‡ºï¼š", output)

except Exception as e:
    print(f"[é”™è¯¯] è°ƒç”¨å¤±è´¥ï¼š{e}")
    print("""
[æ’æŸ¥å»ºè®®]
- 401 é”™è¯¯ï¼šè¯·æ£€æŸ¥ API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ
- ç¡®è®¤ base_url ä¸º https://www.dmxapi.cn/v1
- ç¡®è®¤æ¨¡å‹åç§°æ­£ç¡®ï¼ˆå¦‚ gpt-4o-miniï¼‰
- æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
    """.strip())
```
## LangChain è¿”å›ç¤ºä¾‹2
```json
ğŸ¤– è¾“å‡ºï¼š åŒ—äº¬ä»Šå¤©é˜³å…‰æ˜åªšï¼Œæ°”æ¸©25Â°Cï¼Œå¾®é£æ‹‚é¢ï¼Œå¾ˆé€‚åˆå¤–å‡ºæ´»åŠ¨ã€‚è€Œåœ¨ä¸Šæµ·ï¼Œå¤©æ°”åŒæ ·æ™´æœ—ï¼Œæ°”æ¸©ä¹Ÿæ˜¯25Â°Cï¼Œå¾®é£è½»è½»å¹æ¥ã€‚
è¿™æ ·çš„å¥½å¤©æ°”ï¼Œåˆ†äº«ä¸€å¥æœ‹å‹åœˆæ–‡æ¡ˆå§ï¼šâ€œåœ¨è¿™ä¸ªé˜³å…‰æ´’æ»¡çš„æ—¥å­é‡Œï¼Œå¿ƒæƒ…ä¹Ÿéšä¹‹ç»½æ”¾ã€‚â€â˜€ï¸
```

<p align="center">
  <small>Â© 2025 DMXAPI LangChain</small>
</p>